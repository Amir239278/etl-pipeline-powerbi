# üöï NYC Taxi Services - ETL Pipeline & Business Intelligence

## üìã Contexte

Ce projet d√©montre une **solution BI compl√®te et production-ready** pour l'analyse de donn√©es de taxis √† New York.

L'architecture couvre l'ensemble du pipeline de donn√©es :
- üìÑ Extraction et nettoyage (Python/Pandas)
- üíæ Stockage optimis√© (PostgreSQL + Parquet)
- üìä Visualisation interactive (Power BI)

**Cas d'usage m√©tier** : Analyse des tendances de mobilit√© urbaine, optimisation des flux de taxis, d√©tection d'anomalies.

---

## üí° Donn√©es Utilis√©es

- **Source** : [NYC Yellow Taxi Trip Data (Kaggle)](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data)
- **Volume** : 500K+ trajets quotidiens
- **Variables** : Date/heure, localisation (pickup/dropoff), tarif, distance, dur√©e, nombre de passagers
- **G√©odonn√©es** : GeoJSON pour cartographie des zones

---

## üéØ Objectifs

‚úÖ **Extraction** : T√©l√©charger et importer les donn√©es brutes
‚úÖ **Nettoyage** : G√©rer les valeurs manquantes, les outliers, les anomalies
‚úÖ **Transformation** : Feature engineering, enrichissement g√©ographique
‚úÖ **Optimisation** : Conversion en Parquet, cr√©ation d'index SQL
‚úÖ **Analyse** : Cr√©ation de dashboards Power BI interactifs
‚úÖ **Insights** : Tendances de mobilit√©, patterns temporels, clustering g√©ographique

---

## üõ†Ô∏è Stack Technique

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Data Processing** | Python 3.8+ | Nettoyage, transformation |
| **Libraries** | Pandas, NumPy | Manipulation DataFrames |
| **Database** | PostgreSQL | Stockage structur√© |
| **Format Stockage** | Parquet | Compression & performance |
| **Visualization** | Power BI | Dashboards interactifs |
| **Notebooks** | Jupyter | Documentation & exp√©rimentation |

---

## üìÅ Architecture du Projet

```
etl-pipeline-powerbi/
‚îú‚îÄ‚îÄ data_geojson/                 # Donn√©es g√©ographiques (GeoJSON)
‚îú‚îÄ‚îÄ data_brut/                   # Donn√©es brutes import√©es de Kaggle
‚îú‚îÄ‚îÄ data_clean/                  # Donn√©es nettoy√©es et transform√©es
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_cleaning_step.ipynb      # Nettoyage initial
‚îÇ   ‚îú‚îÄ‚îÄ 02_outliers_identification.ipynb  # D√©tection d'anomalies
‚îÇ   ‚îî‚îÄ‚îÄ 03_convert_parquet.ipynb    # Conversion format optim√©
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ queries.sql                 # Requ√™tes PostgreSQL
‚îú‚îÄ‚îÄ powerbi/
‚îÇ   ‚îî‚îÄ‚îÄ nyc_taxi_report.pbix       # Rapport BI
‚îú‚îÄ‚îÄ .env                         # Variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                    # Documentation
```

---

## üöÄ √âtapes du Pipeline

### 1Ô∏è‚É£ **Extraction & Chargement Initial**

```python
# T√©l√©charger depuis Kaggle
# Placer les fichiers CSV dans data_brut/
# Ex: yellow_tripdata_2023-01.csv
```

### 2Ô∏è‚É£ **Nettoyage des Donn√©es**

- Suppression des doublons
- Gestion des valeurs manquantes
- Conversion des types de donn√©es
- Normalisation des cha√Ænes
- Validation des plages de valeurs

### 3Ô∏è‚É£ **D√©tection des Anomalies**

- Identification des points aberrants (distance, dur√©e, tarif)
- Analyse statistique (quartiles, IQR)
- Flagging des enregistrements douteux
- G√©n√©ration de rapports d'anomalies

### 4Ô∏è‚É£ **Enrichissement G√©ographique**

- Matching avec GeoJSON (NYC zones)
- G√©ocodage des coordonn√©es (latitude/longitude)
- Cr√©ation de variables spatiales (distance, zone)
- Agr√©gation par quartier/district

### 5Ô∏è‚É£ **Optimisation du Stockage**

```python
# Conversion CSV ‚Üí Parquet pour :
# - R√©duction taille fichiers (~80% compression)
# - Acc√©l√©ration lectures
# - Optimisation m√©moire
```

### 6Ô∏è‚É£ **Traitement SQL**

```sql
-- Cr√©ation tables dimension/fact
-- Agr√©gations par temps (jour, heure, zone)
-- Calculs KPI (revenus moyens, vitesse moyenne)
-- Cr√©ation views pour Power BI
```

### 7Ô∏è‚É£ **Visualisation Power BI**

- Dashboards multi-pages (vue g√©n√©rale, d√©tail temporel, zones)
- Filtres interactifs (date, zone, tarif)
- Cartes g√©ographiques des trajets
- Analyses de tendances

---

## üìñ Pr√©requis & Installation

### Outils Obligatoires

```bash
# V√©rifier Python
python --version  # >= 3.8

# Installer PostgreSQL
# https://www.postgresql.org/download/

# Installer Power BI Desktop
# https://powerbi.microsoft.com/fr-fr/desktop/
```

### Setup du Projet

```bash
# 1. Cloner le repo
git clone https://github.com/Amir239278/etl-pipeline-powerbi.git
cd etl-pipeline-powerbi

# 2. Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. Configurer .env
DB_NAME=nyc_taxi
DB_USER=postgres
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432

# 5. Cr√©er la base PostgreSQL
psql -U postgres -c "CREATE DATABASE nyc_taxi;"

# 6. Ex√©cuter migrations SQL
psql -U postgres -d nyc_taxi -f sql/queries.sql
```

### Lancer les Notebooks

```bash
jupyter notebook
# Ex√©cuter dans l'ordre :
# 1. 01_cleaning_step.ipynb
# 2. 02_outliers_identification.ipynb
# 3. 03_convert_parquet.ipynb
```

---

## üìä R√©sultats & KPI

### M√©triques de Nettoyage
- **Doublons supprim√©s** : 0.5%
- **Valeurs manquantes** : <1%
- **Outliers d√©tect√©s** : 3.2%

### Insights M√©tier
- üîß **Pic activit√©** : Jeudi 16h-20h (rush hour)
- üí∞ **Revenu moyen** : $13.50 par trajet
- üìç **Zone active** : Midtown Manhattan
- ‚è±Ô∏è **Temps moyen** : 14 minutes

---

## üìö Comp√©tences D√©montr√©es

‚úì **Data Engineering** : Pipeline ETL complet
‚úì **Python** : Pandas, NumPy, donn√©es volumineuses
‚úì **SQL** : Requ√™tes complexes, optimisation indexes
‚úì **G√©olocalisation** : GeoJSON, clustering spatial
‚úì **BI** : Dashboards, KPI, storytelling
‚úì **Performance** : Optimisation Parquet, requ√™tes SQL
‚úì **Documentation** : Code comment√©, READMEs

---

## üìÑ Licence

MIT License - Libre d'utilisation

---

## üìß Contact

üë§ **Auteur** : Amir - Data Analyst & Engineer
üí¨ **GitHub** : [github.com/Amir239278](https://github.com/Amir239278)
üíº **Recherche** : Alternance Data Engineer - √éle-de-France
üéØ **Formation** : WCS Data Engineer (Mars 2026)
